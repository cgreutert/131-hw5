---
title: "Homework Five: Elastic Net Tuning"
author: "Carly Greutert"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, include=FALSE}
library(tidymodels)
library(generics)
library(glmnet)
library(ggplot2)
library(discrim)
library(corrr)
library(klaR)
library(caret)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(corrplot)
library(ggthemes)
library(cli)
library(recipes)
library(pROC)
library(yardstick)
library(MASS)
library(poissonreg)
library(naivebayes)
tidymodels_prefer()
```

```{r message=FALSE, include=FALSE}
pokemon_old <- read_csv('C:\\Users\\carly\\AppData\\Local\\Temp\\Temp1_homework-5.zip\\homework-5\\data\\Pokemon.csv')
```

1. 
```{r}
library(janitor)
pokemon <- clean_names(pokemon_old)
pokemon
```
After cleaning the names of the data set, I noticed that they were all converted to lower case and all the labels with a period after them change to an underscore. The function clean_names is useful for creating unique labels to reference later. It is also useful they are written similarly.                                                                                     
2.
```{r}
pokemon %>% 
  ggplot(aes(y=type_1)) +
  geom_bar()
length(unique(pokemon$type_1))
pokemon <- filter(pokemon, type_1=="Bug" | type_1=="Fire" | type_1=="Grass" | type_1=="Normal" | type_1=="Water" | type_1=="Psychic")
names <- c('type_1', 'legendary')
pokemon[,names] <- lapply(pokemon[,names], factor)
pokemon$generation <- as.factor(pokemon$generation)
class(pokemon$generation)
```
There are 18 different classes of the outcome. They are all character classes. 
3.
```{r}
set.seed(777)
pokemon_split <- initial_split(pokemon, prop = 0.80, strata = 'type_1')
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)
dim(pokemon_train)
dim(pokemon_test)
pokemon_folds <- vfold_cv(pokemon_train, v = 5, strata=type_1)
```
It is a good idea to stratify the folds on type_1 so that the class ratios are more balanced, we do not want to over or under sample.                                                           
4. 
```{r}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def, pokemon_train) %>% 
  step_dummy(legendary) %>%
  step_dummy(generation) %>%
  step_normalize(all_predictors())
```

5.
```{r}
elastic_grid <- grid_regular(penalty(range = c(-5,5)), mixture(range = c(0,1)), levels= 10)
elasticnet <- multinom_reg(penalty = tune(), mixture = tune()) %>%
              set_mode("classification") %>%
              set_engine("glmnet")
elastic_wf <- workflow() %>% 
  add_recipe(pokemon_recipe) %>% 
  add_model(elasticnet)
```
Across 5 folds, I will be fitting 5 folds * 10 penalties * 10 mixtures = 500 models to the data.

6. 
```{r}
tune_ent <- tune_grid(
  elastic_wf,
  resamples = pokemon_folds, 
  grid = elastic_grid
)
#autoplot(tune_ent)
```

I see that smaller penalty values produce a larger accuracy and ROC AUC.
7.
```{r}
best_penalty <- select_best(tune_ent, metric = "roc_auc")
best_penalty
ent_final <- finalize_workflow(elastic_wf, best_penalty)
ent_final_fit <- fit(ent_final, data = pokemon_train)
augment(ent_final_fit, new_data = pokemon_test)%>%
  yardstick::accuracy(truth = type_1, estimate = .pred_class)
```
8.
```{r}
augment(ent_final_fit, new_data = pokemon_test) %>%
  roc_auc(type_1, estimate = c(.pred_Bug, .pred_Fire, .pred_Water, .pred_Grass, .pred_Normal, .pred_Psychic))

augment(ent_final_fit, new_data = pokemon_test) %>%
roc_curve(type_1, estimate = c(.pred_Bug, .pred_Fire, .pred_Water, .pred_Grass, .pred_Normal, .pred_Psychic)) %>%
autoplot()

augment(ent_final_fit, new_data = pokemon_test) %>%
  conf_mat(truth = type_1, estimate = .pred_class) %>% 
  autoplot(type = "heatmap")
```

I notice that my model is not very good at precting the type of Pokemon. I also see that the model is best at predicting Normal, Psychic, and Fire types. It is very bad at predicting water, grass, and bug. I think this means that Pokemon's statistics does not determine its primary type. It may also mean that types such as water, grass, and bug do not have significant defining features in this data set and are more scattered. 

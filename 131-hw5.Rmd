---
title: "Homework Five: Elastic Net Tuning"
author: "Carly Greutert"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, include=FALSE}
library(tidymodels)
library(generics)
library(glmnet)
library(ggplot2)
library(discrim)
library(corrr)
library(klaR)
library(caret)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(corrplot)
library(ggthemes)
library(cli)
library(recipes)
library(pROC)
library(yardstick)
library(MASS)
library(poissonreg)
library(naivebayes)
tidymodels_prefer()
```

```{r message=FALSE, include=FALSE}
pokemon_old <- read_csv('C:\\Users\\carly\\AppData\\Local\\Temp\\Temp1_homework-5.zip\\homework-5\\data\\Pokemon.csv')
```

1. 
```{r}
library(janitor)
pokemon <- clean_names(pokemon_old)
pokemon
```
After cleaning the names of the data set, I noticed that they were all converted to lower case and all the labels with a period after them change to an underscore. The function clean_names is useful for creating unique labels to reference later. It is also useful they are written similarly.                                                                                     
2.
```{r}
pokemon %>% 
  ggplot(aes(y=type_1)) +
  geom_bar()
length(unique(pokemon$type_1))
pokemon <- filter(pokemon, type_1=="Bug" | type_1=="Fire" | type_1=="Grass" | type_1=="Normal" | type_1=="Water" | type_1=="Psychic")
names <- c('type_1', 'legendary')
pokemon[,names] <- lapply(pokemon[,names], factor)
pokemon$generation <- as.factor(pokemon$generation)
class(pokemon$generation)
```
There are 18 different classes of the outcome. They are all character classes. 
3.
```{r}
set.seed(777)
pokemon_split <- initial_split(pokemon, prop = 0.80, strata = 'type_1')
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)
dim(pokemon_train)
dim(pokemon_test)
pokemon_folds <- vfold_cv(pokemon_train, v = 5, strata=type_1)
```
It is a good idea to stratify the folds on type_1 so that the class ratios are more balanced, we do not want to over or under sample.                                                           
4. 
```{r}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def, pokemon_train) %>% 
  step_dummy(legendary) %>%
  step_dummy(generation) %>%
  step_normalize(all_predictors())
```

5.
```{r}
elastic_grid <- grid_regular(penalty(range = c(-5,5)), mixture(range = c(0,1)), levels= 10)
elasticnet <- multinom_reg(penalty = tune(), mixture = tune()) %>%
              set_mode("classification") %>%
              set_engine("glmnet")
elastic_wf <- workflow() %>% 
  add_recipe(pokemon_recipe) %>% 
  add_model(elasticnet)
```
Across 5 folds, I will be fitting 5 models to the data.

6. 
```{r}
tune_ent <- tune_grid(
  elastic_wf,
  resamples = pokemon_folds, 
  grid = elastic_grid
)
autoplot(tune_ent)
```
